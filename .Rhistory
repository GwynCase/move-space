source('../src/conflicted.R')
options(scipen=999)
#Load some libraries.
library(tidyverse)
library(sf)
library(lubridate)
library(adehabitatHR)
library(ggplot2)
library(extrafont)
# Define some colors.
m <- '#d36135' # Flame
f <- '#689689' # Polished pine
# Load telemetry data.
source('../src/clean_telemetry.R')
# Rename the data frame.
tl <- df
# tl <- read_csv('../data/processed/telemetry_2018-2019.csv')
# How many tags?
tl %>% distinct(site, year(date), id, sex)
# How much data per tag?
tl %>% group_by(id) %>%
mutate(min=min(date), max=max(date), n.points=n(), period=max-min) %>%
distinct(id, site, n.points, min, max, period)
# Define breeding season.
breeding.2018 <- interval(ymd(20180420), ymd(20180915))
breeding.2019 <- interval(ymd(20190420), ymd(20190915))
breeding.2020 <- interval(ymd(20200420), ymd(20200915))
# Select only points that fall within the breeding season.
tl.breeding <- tl %>%
filter(date %within% c(breeding.2018, breeding.2019, breeding.2020))
# Summarize.
tl.breeding %>% group_by(id) %>%
mutate(min=min(date), max=max(date), n.points=n(), period=max-min) %>%
distinct(id, site, n.points, min, max, period) %>%
arrange(site)
# Transform telemetry data to a spatial format.
tl.breeding.sf <- tl.breeding %>% st_as_sf(coords=c('lon', 'lat')) %>%
st_set_crs('+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs') %>%
st_transform("+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs")
# Make 95% & 50% MCPs
mcp <- tl.breeding.sf %>%
#filter(id != 'HAR03') %>%
select(id, geometry) %>%
as_Spatial() %>%
mcp.area(percent=c(50, 95), unin='m', unout='ha', plotit=FALSE) %>%
rownames_to_column(var='percent') %>%
pivot_longer(-percent, names_to='id', values_to='area') %>%
mutate(method='mcp')
# Make 95% and 50% KDEs.
kde <- tl.breeding.sf %>%
#filter(id != 'HAR03') %>%
select(id, geometry) %>%
as_Spatial() %>%
kernelUD() %>%
kernel.area(percent=c(50, 95), unin='m', unout='ha') %>%
rownames_to_column(var='percent') %>%
pivot_longer(-percent, names_to='id', values_to='area') %>%
mutate(method='kde')
# And in the darkness bind them.
homerange <- bind_rows(mcp, kde)
# Add sex info.
homerange <- tl %>% distinct(id, sex) %>% right_join(homerange, by=c('id'))
homerange %>% mutate(group=paste(percent, method, sep='')) %>%
ggplot(aes(x=group, y=area)) +
geom_boxplot() +
theme_classic()
homerange %>% filter(method == 'mcp') %>%
ggplot(aes(x=as.factor(percent), y=area, fill=sex)) +
geom_boxplot() +
labs(title='Home range and core-use area by sex', x='% MCP', y='Area (ha)') +
scale_fill_manual(values=c(f, m)) +
theme_classic() +
theme(text=element_text(family="Lato Semibold"))
homerange %>% filter(method == 'mcp') %>%
group_by(sex, percent) %>%
summarize(n=n(), mean.area=mean(area))
homerange %>% group_by(percent, method) %>%
summarize(mean.area=mean(area))
homerange %>% filter(method == 'kde') %>%
group_by(sex, percent) %>%
summarize(n=n(), mean.area=mean(area))
homerange %>% filter(sex == 'f' & percent == 50)
homerange %>% filter(sex == 'f' & percent == 95)
#write_csv(tl.breeding, '../data/interim/telemetry_problem.csv')
# st_write(mtc.sf, '../data/interim/mtc_breeding_95.shp')
# st_write(max.points, '../data/interim/max_points.shp')
tl %>%
filter(date %within% c(breeding.2018, breeding.2019, breeding.2020))
tl %>%
filter(date %within% breeding.2019)
tl %>%
filter(date %within% c(breeding.2019))
tl %>%
filter(date %within% c(breeding.2019, breeding.2020))
tl %>%
filter(date %within% c(breeding.2018, breeding.2019, breeding.2020))
tl %>%
filter(date %within% c(breeding.2018))
tl %>%
filter(date %within% c(breeding.2018, breeding.2019))
tl %>%
filter(date %within% c(breeding.2018, breeding.2019, breeding.2020))
tl %>%
filter(date %within% c(breeding.2018, breeding.2020))
install.packages('tlocoh')
install.packages('suncalc')
install.packages('moveHMM')
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warnings=FALSE)
# Load some libraries.
library('tidyverse')
library('lubridate')
library('sp')
library('moveHMM')
library('suncalc')
# Read in the data.
df <- read.csv('../data/processed/telem_all.csv',
header=TRUE, stringsAsFactors=FALSE) %>%
drop_na('lat')
# Select just one site to work with.
ska <- df %>% filter(site == 'SKA')
# Convert to sp and specify coordinates.
coordinates(ska) <- c('lon', 'lat')
# Define current projection.
proj4string(ska) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
# Convert to UTM.
ska <- spTransform(ska, CRS('+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs'))
# Rename from lat/lon to x/y.
colnames(ska@coords) <- c('x', 'y')
# Return to data frame because that's what moveHMM wants.
ska <- as.data.frame(ska)
# Send to moveHMM.
data <- prepData(ska, type="UTM", coordNames=c('x','y'))
# Check it out.
hist(data$step)
hist(data$angle)
# First, check if there are any steps with a length of 0.
whichzero <- which(data$step==0)
length(whichzero)/nrow(data)
# Define parameters.
# Mean step length.
mu0 <- c(250, 750)
# Step length standard deviation. Can start with same as mean.
sigma0 <- c(250, 750)
# Step zero-mass, the proportion of steps = 0.
zeromass0 <- c(0.0002, 0.00001)
# Combine into first parameter.
stepPar0 <- c(mu0,sigma0,zeromass0)
# Mean angle.
angleMean0 <- c(pi, 0)
# Angle concentration.
kappa0 <- c(0.5, 3)
# Combine into second parameter.
anglePar0 <- c(angleMean0,kappa0)
# Build model.
m <- fitHMM(data=data, nbStates=2, stepPar0=stepPar0, anglePar0=anglePar0,
formula=~1)
m
# Mean step length.
mu0.3 <- c(5, 250, 1000)
# Step length standard deviation. Can start with same as mean.
sigma0.3 <- c(5, 500, 500)
# Step zero-mass, the proportion of steps = 0.
zeromass0.3 <- c(0.002, 0.0001, 0.00001)
# Combine into first parameter.
stepPar0.3 <- c(mu0.3, sigma0.3, zeromass0.3)
# Mean angle.
angleMean0.3 <- c(pi, pi/2, 0)
# Angle concentration.
kappa0.3 <- c(0.1, 0.5, 3)
# Combine into second parameter.
anglePar0.3 <- c(angleMean0.3, kappa0.3)
# Fit the model.
m3 <- fitHMM(data=data, nbStates=3, stepPar0=stepPar0.3, anglePar0=anglePar0.3, formula=~1)
# Select just one site to work with.
ska <- df %>% filter(site == 'SKA')
# Do the datetime thing.
ska$date <- date(ska$date)
ska$datetime <- ymd_hms(ska$datetime)
# Get sunrise and sunset times.
ska <-  getSunlightTimes(data=ska, keep=c('sunrise', 'sunset'),
tz='America/Vancouver')
# Designate points as day or night.
ska$diff.rise <- as.numeric(difftime(ska$datetime,
ska$sunrise, units='hours'))
ska
View(ska)
difftime(ska$datetime,
ska$sunrise, units='hours'))
difftime(ska$datetime,
ska$sunrise, units='hours')
as.difftime(ska$datetime,
ska$sunrise, units='hours')
class(ska$datetime)
# Select just one site to work with.
ska <- df %>% filter(site == 'SKA')
# Do the datetime thing.
ska$date <- date(ska$date)
ska$datetime <- ymd_hms(ska$datetime)
# Get sunrise and sunset times.
ska.times <-  getSunlightTimes(data=ska, keep=c('sunrise', 'sunset'),
tz='America/Vancouver')
View(ska.times)
left_join(ska, ska.times, by=c('date', 'lat', 'lon'))
# Bind to location points.
ska <- left_join(ska, ska.times, by=c('date', 'lat', 'lon'))
# Designate points as day or night.
ska$diff.rise <- as.numeric(difftime(ska$datetime,
ska$sunrise, units='hours'))
ska$diff.set <- as.numeric(difftime(ska$datetime,
ska$sunset, units='hours'))
ska$t.period <- case_when(
ska$diff.rise >= 0 & ska$diff.set <= 0 ~ 'day',
TRUE ~ 'night'
)
ska <- ska %>% filter(t.period == 'day')
# Convert to sp and specify coordinates.
coordinates(ska) <- c('lon', 'lat')
# Define current projection.
proj4string(ska) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
# Convert to UTM.
ska <- spTransform(ska, CRS('+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs'))
# Rename from lat/lon to x/y.
colnames(ska@coords) <- c('x', 'y')
# Return to data frame because that's what moveHMM wants.
ska <- as.data.frame(ska)
# Send to moveHMM.
data <- prepData(ska, type="UTM", coordNames=c('x','y'))
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warnings=FALSE)
# Load some libraries.
library('tidyverse')
library('lubridate')
library('sp')
library('moveHMM')
library('suncalc')
# Read in the data.
df <- read.csv('../data/processed/telem_all.csv',
header=TRUE, stringsAsFactors=FALSE) %>%
drop_na('lat')
# Select just one site to work with.
ska <- df %>% filter(site == 'SKA')
# Convert to sp and specify coordinates.
coordinates(ska) <- c('lon', 'lat')
# Define current projection.
proj4string(ska) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
# Convert to UTM.
ska <- spTransform(ska, CRS('+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs'))
# Rename from lat/lon to x/y.
colnames(ska@coords) <- c('x', 'y')
# Return to data frame because that's what moveHMM wants.
ska <- as.data.frame(ska)
# Send to moveHMM.
data <- prepData(ska, type="UTM", coordNames=c('x','y'))
# Check it out.
hist(data$step)
hist(data$angle)
# First, check if there are any steps with a length of 0.
whichzero <- which(data$step==0)
length(whichzero)/nrow(data)
# Define parameters.
# Mean step length.
mu0 <- c(250, 750)
# Step length standard deviation. Can start with same as mean.
sigma0 <- c(250, 750)
# Step zero-mass, the proportion of steps = 0.
zeromass0 <- c(0.0002, 0.00001)
# Combine into first parameter.
stepPar0 <- c(mu0,sigma0,zeromass0)
# Mean angle.
angleMean0 <- c(pi, 0)
# Angle concentration.
kappa0 <- c(0.5, 3)
# Combine into second parameter.
anglePar0 <- c(angleMean0,kappa0)
# Build model.
m <- fitHMM(data=data, nbStates=2, stepPar0=stepPar0, anglePar0=anglePar0,
formula=~1)
m
# Mean step length.
mu0.3 <- c(5, 250, 1000)
# Step length standard deviation. Can start with same as mean.
sigma0.3 <- c(5, 500, 500)
# Step zero-mass, the proportion of steps = 0.
zeromass0.3 <- c(0.002, 0.0001, 0.00001)
# Combine into first parameter.
stepPar0.3 <- c(mu0.3, sigma0.3, zeromass0.3)
# Mean angle.
angleMean0.3 <- c(pi, pi/2, 0)
# Angle concentration.
kappa0.3 <- c(0.1, 0.5, 3)
# Combine into second parameter.
anglePar0.3 <- c(angleMean0.3, kappa0.3)
# Fit the model.
m3 <- fitHMM(data=data, nbStates=3, stepPar0=stepPar0.3, anglePar0=anglePar0.3, formula=~1)
# Select just one site to work with.
ska <- df %>% filter(site == 'SKA')
# Do the datetime thing.
ska$date <- date(ska$date)
ska$datetime <- ymd_hms(ska$datetime)
# Get sunrise and sunset times.
ska.times <-  getSunlightTimes(data=ska, keep=c('sunrise', 'sunset'),
tz='America/Vancouver')
# Bind to location points.
ska <- left_join(ska, ska.times, by=c('date', 'lat', 'lon'))
# Designate points as day or night.
ska$diff.rise <- as.numeric(difftime(ska$datetime,
ska$sunrise, units='hours'))
ska$diff.set <- as.numeric(difftime(ska$datetime,
ska$sunset, units='hours'))
ska$t.period <- case_when(
ska$diff.rise >= 0 & ska$diff.set <= 0 ~ 'day',
TRUE ~ 'night'
)
ska <- ska %>% filter(t.period == 'day')
# Convert to sp and specify coordinates.
coordinates(ska) <- c('lon', 'lat')
# Define current projection.
proj4string(ska) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
# Convert to UTM.
ska <- spTransform(ska, CRS('+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs'))
# Rename from lat/lon to x/y.
colnames(ska@coords) <- c('x', 'y')
# Return to data frame because that's what moveHMM wants.
ska <- as.data.frame(ska)
# Send to moveHMM.
data <- prepData(ska, type="UTM", coordNames=c('x','y'))
# First, check if there are any steps with a length of 0.
whichzero <- which(data$step==0)
length(whichzero)/nrow(data)
# Mean step length.
mu0 <- c(1000, 2000)
# Also tried: 250 & 750, 500 & 1500
# Step length standard deviation. Can start with same as mean.
sigma0 <- c(1000, 250)
# Also tried: 250 & 250
# Step zero-mass, the proportion of steps = 0.
zeromass0 <- c(0.0004, 0)
# Combine into first parameter.
stepPar0 <- c(mu0, sigma0, zeromass0)
# Mean angle.
angleMean0 <- c(pi, 0)
# Angle concentration.
kappa0 <- c(0.001, 5)
# Also tried: 0.5 & 3, 0.1 & 5
# Combine into second parameter.
anglePar0 <- c(angleMean0, kappa0)
# Build model.
m <- fitHMM(data=data, nbStates=2, stepPar0=stepPar0, anglePar0=anglePar0,
formula=~1)
m
# Make a list of the files containing "HAR".
file.list <- list.files('../data/raw', pattern='HAR', full.names=TRUE)
file.list
# Use the function to read in all the files in the file list all at once,
# and put all their contents into a single data frame.
df <- lapply(file.list, read)
# Here's the function.
read <- function(x) {
read_delim(x, ';')
}
# Use the function to read in all the files in the file list all at once,
# and put all their contents into a single data frame.
df <- lapply(file.list, read)
# Use the function to read in all the files in the file list all at once,
# and put all their contents into a single data frame.
df <- lapply(file.list, read)
str(df)
library('tidyverse')
# Make a list of the files containing "HAR".
file.list <- list.files('../data/raw', pattern='HAR', full.names=TRUE)
file.list
# Here's the function.
read <- function(x) {
read_delim(x, ';')
}
# Use the function to read in all the files in the file list all at once,
# and put all their contents into a single data frame.
df <- lapply(file.list, read)
str(df)
df[[7]]
# Drop the seventh item from the data frame.
df[[7]] <- NULL
df <- bind_rows(df) %>%
mutate(Speed=as.numeric(Speed))
# Read in HAR07 csv.
HAR07 <- read_csv("../data/raw/HAR07_RAW_2018-07-08_2019-05-09.csv")
# Let's take a peek at it.
head(HAR07)
head(df)
HAR07 <- HAR07 %>%
rename(Latitude=Lat,
Longitude=Long,
`Searching time`=SearchT,
`Logger ID`=LoggerID,
Temperature=Temp,
`No GPS - timeout`=NoGPS)
# Make a single datetime column.
df$datetime <-
strptime(paste(df$Year, df$Month, df$Day, df$Hour, df$Minute, df$Second),
format='%Y%m%d%H%M%S', tz='UTC')
# Then convert the datetime to the correct timezone.
df$datetime <- with_tz(df$datetime, tzone = "America/Los_Angeles")
# For some things, I find it helpful to have a separate "date" and "time" column.
df$date <- date(df$datetime)
df$time <- format(ymd_hms(df$datetime), '%H:%M%S')
library('tidyverse')
# Make a list of the files containing "HAR".
file.list <- list.files('../data/raw', pattern='HAR', full.names=TRUE)
file.list
# Here's the function.
read <- function(x) {
read_delim(x, ';')
}
# Use the function to read in all the files in the file list all at once,
# and put all their contents into a single data frame.
df <- lapply(file.list, read)
str(df)
# Drop the seventh item from the data frame.
df[[7]] <- NULL
# Reshape the data frame and tidy up.
df <- bind_rows(df) %>%
mutate(Speed=as.numeric(Speed))
# Read in HAR07 csv.
HAR07 <- read_csv("../data/raw/HAR07_RAW_2018-07-08_2019-05-09.csv")
# Let's take a peek at it.
head(HAR07)
head(df)
# Rename columns for consistency.
HAR07 <- HAR07 %>%
rename(Latitude=Lat,
Longitude=Long,
`Searching time`=SearchT,
`Logger ID`=LoggerID,
Temperature=Temp,
`No GPS - timeout`=NoGPS)
# Drop all 2019 points.
HAR07 <- filter(HAR07, Year != 2019)
# Add to the main dataframe.
df <- bind_rows(df, HAR07)
# Make a single datetime column.
# Note that the timezone recorded by the tags is UTC, so that's specified here.
df$datetime <-
strptime(paste(df$Year, df$Month, df$Day, df$Hour, df$Minute, df$Second),
format='%Y%m%d%H%M%S', tz='UTC')
# Then convert the datetime to the correct timezone.
df$datetime <- with_tz(df$datetime, tzone = "America/Los_Angeles")
library('tidyverse')
# Then convert the datetime to the correct timezone.
df$datetime <- with_tz(df$datetime, tzone = "America/Los_Angeles")
library(lubridate)
# Then convert the datetime to the correct timezone.
df$datetime <- with_tz(df$datetime, tzone = "America/Los_Angeles")
# Make a single datetime column.
# Note that the timezone recorded by the tags is UTC, so that's specified here.
df$datetime <-
strptime(paste(df$Year, df$Month, df$Day, df$Hour, df$Minute, df$Second),
format='%Y%m%d%H%M%S', tz='UTC')
# Then convert the datetime to the correct timezone.
df$datetime <- with_tz(df$datetime, tzone = "America/Los_Angeles")
# For some things, I find it helpful to have a separate "date" and "time" column.
df$date <- date(df$datetime)
df$time <- format(ymd_hms(df$datetime), '%H:%M%S')
# Make a list of all the extra columns we don't need.
e.cols <- c('Month', 'Day', 'Hour', 'Minute', 'Second',
'Altitude', 'Div up', 'Div down', 'No GPS - diving', 'Diving duration',
'Raw latitude', 'Raw Longitude', 'Decision voltage', 'Milisecond',
'Acc_X', 'Acc_Y', 'Acc_Z')
# Remove them from the data frame.
df <- select(df, !any_of(e.cols))
# Rename the remaining columns in a reasonable, consistent way.
df <- rename(df, id='Logger ID',
lat='Latitude',
lon='Longitude',
speed='Speed',
s.time='Searching time',
volt='Voltage',
temp='Temperature',
no.fix='No GPS - timeout',
at.base='In range',
year='Year',
datetime=datetime)
# Read in table of nest coordinates.
telemetry.sites <- read_csv('../data/processed/telemetry_sites.csv')
```{r message=FALSE}
# Read in table of nest coordinates.
telemetry.sites <- read_csv('../data/processed/telemetry_sites.csv')
# Take a quick look.
head(telemetry.sites)
# Look again.
head(nest.coords)
# Rearrange the nest coordinates a little so they're easier to join with the location data.
nest.coords <- select(telemetry.sites, lat, lon, m_tag, f_tag, year, site, nest) %>%
pivot_longer(!c(lat, lon, year, site, nest), names_to='sex', values_to='id') %>%
drop_na(id) %>% rename(n.lat=lat, n.lon=lon) %>%
mutate(sex=case_when(
sex == 'm_tag' ~ 'm',
sex == 'f_tag' ~ 'f'
))
# Look again.
head(nest.coords)
# Now join to main data frame.
df <- left_join(df, nest.coords, by=c('id', 'year'))
# Fill missing coordinates when bird is at the nest.
df <- df %>% mutate(
lat=case_when(
at.base == 1 & is.na(lat) ~ n.lat,
TRUE ~ lat
),
lon=case_when(
at.base == 1 & is.na(lon) ~ n.lon,
TRUE ~ lon
)
)
